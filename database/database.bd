{"title":"BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding<br>","author":null,"abstract":"We   introduce   a   new   language   representa- tion  model  calledBERT,  which  stands  for BidirectionalEncoderRepresentations  from Transformers.  Unlike recent language repre- sentation  models  (Peters  et  al.,  2018a;  Rad- ford  et  al.,  2018),  BERT  is  designed  to  pre- train  deep  bidirectional  representations  from unlabeled text by jointly conditioning on both left  and  right  context  in  all  layers.   As  a  re- sult, the pre-trained BERT model can be fine- tuned  with  just  one  additional  output  layer to  create  state-of-the-art  models  for  a  wide range of tasks, such as question answering and language  inference,  without  substantial  task- specific architecture modifications. BERT is conceptually simple and empirically powerful.   It  obtains  new  state-of-the-art  re- sults  on  eleven  natural  language  processing tasks,  including  pushing  the  GLUE  score  to 80.5%  (7.7%  point  absolute  improvement), MultiNLI  accuracy  to  86.7%  (4.6%  absolute improvement), SQuAD v1.1 question answer- ing  Test  F1  to  93.2  (1.5  point  absolute  im- provement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement).","publisher":null,"url":null,"path":"/Users/wubolun/Bowen/SJTU/Netsec&TS Lab/papers/nlp/BERT.pdf","tags":["AI","NLP","MCBG"],"remark":null,"_id":"ASFzJiShWmjSMpeM"}
{"title":"HOW POWERFUL ARE GRAPH NEURAL NETWORKS?","author":null,"abstract":"Graph Neural Networks (GNNs) are an effective framework for representation learning of graphs. GNNs follow a neighborhood aggregation scheme, where the representation vector of a node is computed by recursively aggregating and trans- forming representation vectors of its neighboring nodes. Many GNN variants have been proposed and have achieved state-of-the-art results on both node and graph classification tasks. However, despite GNNs revolutionizing graph representation learning, there is limited understanding of their representational properties and limitations. Here, we present a theoretical framework for analyzing the expressive power of GNNs to capture different graph structures.  Our results characterize the discriminative power of popular GNN variants, such as Graph Convolutional Networks and GraphSAGE, and show that they cannot learn to distinguish certain simple graph structures.  We then develop a simple architecture that is provably the most expressive among the class of GNNs and is as powerful as the Weisfeiler- Lehman graph isomorphism test. We empirically validate our theoretical findings on a number of graph classification benchmarks, and demonstrate that our model achieves state-of-the-art performance.","publisher":null,"url":null,"path":"/Users/wubolun/Bowen/SJTU/Netsec&TS Lab/papers/gnn/ICLR_GIN.pdf","tags":["AI","GNN","MCBG"],"remark":null,"_id":"Foa47FDLM1zA25bi"}
{"title":"UNICORN: Runtime Provenance-Based Detector for Advanced Persistent Threats","author":null,"abstract":"Advanced Persistent Threats (APTs) are difficult to detect  due  to  their  “low-and-slow”  attack  patterns  and  frequent use  of  zero-day  exploits.  We  present  UNICORN,  an  anomaly- based  APT  detector  that  effectively  leverages  data  provenance analysis. From modeling to detection, UNICORNtailors its design specifically   for   the   unique   characteristics   of   APTs.   Through extensive  yet  time-efficient  graph  analysis,  UNICORNexplores provenance  graphs  that  provide  rich  contextual  and  historical information to identify stealthy anomalous activities without pre- defined  attack  signatures.  Using  a  graph  sketching  technique,  it summarizes long-running system execution with space efficiency to  combat  slow-acting  attacks  that  take  place  over  a  long  time span. UNICORNfurther improves its detection capability using a novel modeling approach to understand long-term behavior as the system evolves. Our evaluation shows that UNICORNoutperforms an existing state-of-the-art APT detection system and detects real- life  APT  scenarios  with  high  accuracy.","publisher":null,"url":null,"path":"/Users/wubolun/Bowen/SJTU/Netsec&TS Lab/papers/apt/UNICORN Runtime Provenance-Based Detector for Advanced Persistent Threats.pdf","tags":["APT-Detection","APT"],"remark":null,"_id":"ctLah1TQjdf1HmkN"}
{"title":"HOLMES: Real-time APT Detection through Correlation of Suspicious Information Flows<br>","author":null,"abstract":"In  this  paper,  we  presentHOLMES,  a  system  that implements  a  new  approach  to  the  detection  of  Advanced  and Persistent  Threats  (APTs).HOLMESis  inspired  by  several  case studies  of  real-world  APTs  that  highlight  some  common  goals of   APT   actors.   In   a   nutshell,HOLMESaims   to   produce   a detection  signal  that  indicates  the  presence  of  a  coordinated set  of  activities  that  are  part  of  an  APT  campaign.  One  of  the main  challenges  addressed  by  our  approach  involves  developing a  suite  of  techniques  that  make  the  detection  signal  robust  and reliable.  At  a  high-level,  the  techniques  we  develop  effectively leverage thecorrelation between suspicious information flowsthat arise  during  an  attacker  campaign.  In  addition  to  its  detection capability,HOLMESis also able to generate a high-level graph that summarizes the attacker’s actions in real-time. This graph can be used by an analyst for an effective cyber response. An evaluation of  our  approach  against  some  real-world  APTs  indicates  that HOLMEScan detect APT campaigns with high precision and low false  alarm  rate.  The  compact  high-level  graphs  produced  by HOLMESeffectively summarizes an ongoing attack campaign and can  assist  real-time  cyber-response  operations.","publisher":null,"url":null,"path":"/Users/wubolun/Bowen/SJTU/Netsec&TS Lab/papers/apt/HOLMES：Real-time APT Detection through Correlatio.pdf","tags":["APT","APT-Detection"],"remark":null,"_id":"eIqMfU03iyMX4RCy"}
